//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31442593
// Cuda compilation tools, release 11.7, V11.7.99
// Based on NVVM 7.0.1
//

.version 7.7
.target sm_52
.address_size 64

	// .globl	copy_kernel

.visible .entry copy_kernel(
	.param .u32 copy_kernel_param_0,
	.param .u64 copy_kernel_param_1,
	.param .u32 copy_kernel_param_2,
	.param .u32 copy_kernel_param_3,
	.param .u64 copy_kernel_param_4,
	.param .u32 copy_kernel_param_5,
	.param .u32 copy_kernel_param_6
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<15>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r6, [copy_kernel_param_0];
	ld.param.u64 	%rd1, [copy_kernel_param_1];
	ld.param.u32 	%r2, [copy_kernel_param_2];
	ld.param.u32 	%r3, [copy_kernel_param_3];
	ld.param.u64 	%rd2, [copy_kernel_param_4];
	ld.param.u32 	%r4, [copy_kernel_param_5];
	ld.param.u32 	%r5, [copy_kernel_param_6];
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %nctaid.x;
	mov.u32 	%r9, %ctaid.y;
	mad.lo.s32 	%r10, %r9, %r8, %r7;
	mov.u32 	%r11, %ntid.x;
	mov.u32 	%r12, %tid.x;
	mad.lo.s32 	%r1, %r10, %r11, %r12;
	setp.ge.s32 	%p1, %r1, %r6;
	@%p1 bra 	$L__BB0_2;

	cvta.to.global.u64 	%rd3, %rd1;
	mad.lo.s32 	%r13, %r1, %r3, %r2;
	mul.wide.s32 	%rd4, %r13, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f32 	%f1, [%rd5];
	mad.lo.s32 	%r14, %r1, %r5, %r4;
	cvta.to.global.u64 	%rd6, %rd2;
	mul.wide.s32 	%rd7, %r14, 4;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f32 	[%rd8], %f1;

$L__BB0_2:
	ret;

}
	// .globl	fill_kernel
.visible .entry fill_kernel(
	.param .u32 fill_kernel_param_0,
	.param .f32 fill_kernel_param_1,
	.param .u64 fill_kernel_param_2,
	.param .u32 fill_kernel_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<11>;
	.reg .b64 	%rd<5>;


	ld.param.u32 	%r3, [fill_kernel_param_0];
	ld.param.f32 	%f1, [fill_kernel_param_1];
	ld.param.u64 	%rd1, [fill_kernel_param_2];
	ld.param.u32 	%r2, [fill_kernel_param_3];
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %nctaid.x;
	mov.u32 	%r6, %ctaid.y;
	mad.lo.s32 	%r7, %r6, %r5, %r4;
	mov.u32 	%r8, %ntid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r1, %r7, %r8, %r9;
	setp.ge.s32 	%p1, %r1, %r3;
	@%p1 bra 	$L__BB1_2;

	cvta.to.global.u64 	%rd2, %rd1;
	mul.lo.s32 	%r10, %r1, %r2;
	mul.wide.s32 	%rd3, %r10, 4;
	add.s64 	%rd4, %rd2, %rd3;
	st.global.f32 	[%rd4], %f1;

$L__BB1_2:
	ret;

}
	// .globl	mul_kernel
.visible .entry mul_kernel(
	.param .u32 mul_kernel_param_0,
	.param .u64 mul_kernel_param_1,
	.param .u32 mul_kernel_param_2,
	.param .u64 mul_kernel_param_3,
	.param .u32 mul_kernel_param_4
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r4, [mul_kernel_param_0];
	ld.param.u64 	%rd1, [mul_kernel_param_1];
	ld.param.u32 	%r2, [mul_kernel_param_2];
	ld.param.u64 	%rd2, [mul_kernel_param_3];
	ld.param.u32 	%r3, [mul_kernel_param_4];
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %nctaid.x;
	mov.u32 	%r7, %ctaid.y;
	mad.lo.s32 	%r8, %r7, %r6, %r5;
	mov.u32 	%r9, %ntid.x;
	mov.u32 	%r10, %tid.x;
	mad.lo.s32 	%r1, %r8, %r9, %r10;
	setp.ge.s32 	%p1, %r1, %r4;
	@%p1 bra 	$L__BB2_2;

	cvta.to.global.u64 	%rd3, %rd1;
	mul.lo.s32 	%r11, %r1, %r2;
	mul.wide.s32 	%rd4, %r11, 4;
	add.s64 	%rd5, %rd3, %rd4;
	mul.lo.s32 	%r12, %r1, %r3;
	cvta.to.global.u64 	%rd6, %rd2;
	mul.wide.s32 	%rd7, %r12, 4;
	add.s64 	%rd8, %rd6, %rd7;
	ld.global.f32 	%f1, [%rd8];
	ld.global.f32 	%f2, [%rd5];
	mul.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd8], %f3;

$L__BB2_2:
	ret;

}
	// .globl	add_kernel
.visible .entry add_kernel(
	.param .u32 add_kernel_param_0,
	.param .f32 add_kernel_param_1,
	.param .u64 add_kernel_param_2,
	.param .u32 add_kernel_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<11>;
	.reg .b64 	%rd<5>;


	ld.param.u32 	%r3, [add_kernel_param_0];
	ld.param.f32 	%f1, [add_kernel_param_1];
	ld.param.u64 	%rd1, [add_kernel_param_2];
	ld.param.u32 	%r2, [add_kernel_param_3];
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %nctaid.x;
	mov.u32 	%r6, %ctaid.y;
	mad.lo.s32 	%r7, %r6, %r5, %r4;
	mov.u32 	%r8, %ntid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r1, %r7, %r8, %r9;
	setp.ge.s32 	%p1, %r1, %r3;
	@%p1 bra 	$L__BB3_2;

	cvta.to.global.u64 	%rd2, %rd1;
	mul.lo.s32 	%r10, %r1, %r2;
	mul.wide.s32 	%rd3, %r10, 4;
	add.s64 	%rd4, %rd2, %rd3;
	ld.global.f32 	%f2, [%rd4];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd4], %f3;

$L__BB3_2:
	ret;

}
	// .globl	scal_kernel
.visible .entry scal_kernel(
	.param .u32 scal_kernel_param_0,
	.param .f32 scal_kernel_param_1,
	.param .u64 scal_kernel_param_2,
	.param .u32 scal_kernel_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<11>;
	.reg .b64 	%rd<5>;


	ld.param.u32 	%r3, [scal_kernel_param_0];
	ld.param.f32 	%f1, [scal_kernel_param_1];
	ld.param.u64 	%rd1, [scal_kernel_param_2];
	ld.param.u32 	%r2, [scal_kernel_param_3];
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %nctaid.x;
	mov.u32 	%r6, %ctaid.y;
	mad.lo.s32 	%r7, %r6, %r5, %r4;
	mov.u32 	%r8, %ntid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r1, %r7, %r8, %r9;
	setp.ge.s32 	%p1, %r1, %r3;
	@%p1 bra 	$L__BB4_2;

	cvta.to.global.u64 	%rd2, %rd1;
	mul.lo.s32 	%r10, %r1, %r2;
	mul.wide.s32 	%rd3, %r10, 4;
	add.s64 	%rd4, %rd2, %rd3;
	ld.global.f32 	%f2, [%rd4];
	mul.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd4], %f3;

$L__BB4_2:
	ret;

}
	// .globl	pow_kernel
.visible .entry pow_kernel(
	.param .u32 pow_kernel_param_0,
	.param .f32 pow_kernel_param_1,
	.param .u64 pow_kernel_param_2,
	.param .u32 pow_kernel_param_3,
	.param .u64 pow_kernel_param_4,
	.param .u32 pow_kernel_param_5
)
{
	.reg .pred 	%p<29>;
	.reg .f32 	%f<108>;
	.reg .b32 	%r<37>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r4, [pow_kernel_param_0];
	ld.param.f32 	%f16, [pow_kernel_param_1];
	ld.param.u64 	%rd2, [pow_kernel_param_2];
	ld.param.u32 	%r2, [pow_kernel_param_3];
	ld.param.u64 	%rd3, [pow_kernel_param_4];
	ld.param.u32 	%r3, [pow_kernel_param_5];
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %nctaid.x;
	mov.u32 	%r7, %ctaid.y;
	mad.lo.s32 	%r8, %r7, %r6, %r5;
	mov.u32 	%r9, %ntid.x;
	mov.u32 	%r10, %tid.x;
	mad.lo.s32 	%r1, %r8, %r9, %r10;
	setp.ge.s32 	%p2, %r1, %r4;
	@%p2 bra 	$L__BB5_16;

	cvta.to.global.u64 	%rd4, %rd2;
	cvta.to.global.u64 	%rd1, %rd3;
	mul.lo.s32 	%r11, %r1, %r2;
	mul.wide.s32 	%rd5, %r11, 4;
	add.s64 	%rd6, %rd4, %rd5;
	mul.f32 	%f18, %f16, 0f3F000000;
	cvt.rzi.f32.f32 	%f19, %f18;
	add.f32 	%f20, %f19, %f19;
	sub.f32 	%f21, %f16, %f20;
	abs.f32 	%f1, %f21;
	ld.global.f32 	%f2, [%rd6];
	abs.f32 	%f3, %f2;
	setp.lt.f32 	%p3, %f3, 0f00800000;
	mul.f32 	%f22, %f3, 0f4B800000;
	selp.f32 	%f23, %f22, %f3, %p3;
	selp.f32 	%f24, 0fC3170000, 0fC2FE0000, %p3;
	mov.b32 	%r12, %f23;
	and.b32  	%r13, %r12, 8388607;
	or.b32  	%r14, %r13, 1065353216;
	mov.b32 	%f25, %r14;
	shr.u32 	%r15, %r12, 23;
	cvt.rn.f32.u32 	%f26, %r15;
	add.f32 	%f27, %f24, %f26;
	setp.gt.f32 	%p4, %f25, 0f3FB504F3;
	mul.f32 	%f28, %f25, 0f3F000000;
	add.f32 	%f29, %f27, 0f3F800000;
	selp.f32 	%f30, %f29, %f27, %p4;
	selp.f32 	%f31, %f28, %f25, %p4;
	add.f32 	%f32, %f31, 0fBF800000;
	add.f32 	%f33, %f31, 0f3F800000;
	rcp.approx.ftz.f32 	%f34, %f33;
	add.f32 	%f35, %f32, %f32;
	mul.f32 	%f36, %f35, %f34;
	mul.f32 	%f37, %f36, %f36;
	mov.f32 	%f38, 0f3C4CAF63;
	mov.f32 	%f39, 0f3B18F0FE;
	fma.rn.f32 	%f40, %f39, %f37, %f38;
	mov.f32 	%f41, 0f3DAAAABD;
	fma.rn.f32 	%f42, %f40, %f37, %f41;
	mul.rn.f32 	%f43, %f42, %f37;
	mul.rn.f32 	%f44, %f43, %f36;
	sub.f32 	%f45, %f32, %f36;
	add.f32 	%f46, %f45, %f45;
	neg.f32 	%f47, %f36;
	fma.rn.f32 	%f48, %f47, %f32, %f46;
	mul.rn.f32 	%f49, %f34, %f48;
	add.f32 	%f50, %f44, %f36;
	sub.f32 	%f51, %f36, %f50;
	add.f32 	%f52, %f44, %f51;
	add.f32 	%f53, %f49, %f52;
	add.f32 	%f54, %f50, %f53;
	sub.f32 	%f55, %f50, %f54;
	add.f32 	%f56, %f53, %f55;
	mov.f32 	%f57, 0f3F317200;
	mul.rn.f32 	%f58, %f30, %f57;
	mov.f32 	%f59, 0f35BFBE8E;
	mul.rn.f32 	%f60, %f30, %f59;
	add.f32 	%f61, %f58, %f54;
	sub.f32 	%f62, %f58, %f61;
	add.f32 	%f63, %f54, %f62;
	add.f32 	%f64, %f56, %f63;
	add.f32 	%f65, %f60, %f64;
	add.f32 	%f66, %f61, %f65;
	sub.f32 	%f67, %f61, %f66;
	add.f32 	%f68, %f65, %f67;
	abs.f32 	%f4, %f16;
	setp.gt.f32 	%p5, %f4, 0f77F684DF;
	mul.f32 	%f69, %f16, 0f39000000;
	selp.f32 	%f70, %f69, %f16, %p5;
	mul.rn.f32 	%f71, %f70, %f66;
	neg.f32 	%f72, %f71;
	fma.rn.f32 	%f73, %f70, %f66, %f72;
	fma.rn.f32 	%f74, %f70, %f68, %f73;
	mov.f32 	%f75, 0f00000000;
	fma.rn.f32 	%f76, %f75, %f66, %f74;
	add.rn.f32 	%f77, %f71, %f76;
	neg.f32 	%f78, %f77;
	add.rn.f32 	%f79, %f71, %f78;
	add.rn.f32 	%f80, %f79, %f76;
	mov.b32 	%r16, %f77;
	setp.eq.s32 	%p6, %r16, 1118925336;
	add.s32 	%r17, %r16, -1;
	mov.b32 	%f81, %r17;
	add.f32 	%f82, %f80, 0f37000000;
	selp.f32 	%f5, %f82, %f80, %p6;
	selp.f32 	%f83, %f81, %f77, %p6;
	mov.f32 	%f84, 0f3FB8AA3B;
	mul.rn.f32 	%f85, %f83, %f84;
	cvt.rzi.f32.f32 	%f86, %f85;
	abs.f32 	%f87, %f86;
	setp.gt.f32 	%p7, %f87, 0f42FC0000;
	mov.b32 	%r18, %f86;
	and.b32  	%r19, %r18, -2147483648;
	or.b32  	%r20, %r19, 1123811328;
	mov.b32 	%f88, %r20;
	selp.f32 	%f89, %f88, %f86, %p7;
	mov.f32 	%f90, 0fBF317218;
	fma.rn.f32 	%f91, %f89, %f90, %f83;
	mov.f32 	%f92, 0f3102E308;
	fma.rn.f32 	%f93, %f89, %f92, %f91;
	mul.f32 	%f94, %f93, 0f3FB8AA3B;
	add.f32 	%f95, %f89, 0f4B40007F;
	mov.b32 	%r21, %f95;
	shl.b32 	%r22, %r21, 23;
	mov.b32 	%f96, %r22;
	ex2.approx.ftz.f32 	%f97, %f94;
	mul.f32 	%f6, %f97, %f96;
	setp.eq.f32 	%p8, %f6, 0f7F800000;
	mov.f32 	%f105, 0f7F800000;
	@%p8 bra 	$L__BB5_3;

	fma.rn.f32 	%f105, %f6, %f5, %f6;

$L__BB5_3:
	setp.lt.f32 	%p9, %f2, 0f00000000;
	setp.eq.f32 	%p10, %f1, 0f3F800000;
	and.pred  	%p1, %p9, %p10;
	setp.eq.f32 	%p11, %f2, 0f00000000;
	@%p11 bra 	$L__BB5_7;
	bra.uni 	$L__BB5_4;

$L__BB5_7:
	add.f32 	%f101, %f2, %f2;
	mov.b32 	%r25, %f101;
	selp.b32 	%r26, %r25, 0, %p10;
	or.b32  	%r27, %r26, 2139095040;
	setp.lt.f32 	%p15, %f16, 0f00000000;
	selp.b32 	%r28, %r27, %r26, %p15;
	mov.b32 	%f107, %r28;
	bra.uni 	$L__BB5_8;

$L__BB5_4:
	mov.b32 	%r23, %f105;
	xor.b32  	%r24, %r23, -2147483648;
	mov.b32 	%f98, %r24;
	selp.f32 	%f107, %f98, %f105, %p1;
	setp.geu.f32 	%p12, %f2, 0f00000000;
	@%p12 bra 	$L__BB5_8;

	cvt.rzi.f32.f32 	%f99, %f16;
	setp.eq.f32 	%p13, %f99, %f16;
	@%p13 bra 	$L__BB5_8;

	mov.f32 	%f107, 0f7FFFFFFF;

$L__BB5_8:
	add.f32 	%f102, %f3, %f4;
	mov.b32 	%r29, %f102;
	setp.lt.s32 	%p16, %r29, 2139095040;
	@%p16 bra 	$L__BB5_15;

	setp.gtu.f32 	%p17, %f3, 0f7F800000;
	setp.gtu.f32 	%p18, %f4, 0f7F800000;
	or.pred  	%p19, %p17, %p18;
	@%p19 bra 	$L__BB5_14;
	bra.uni 	$L__BB5_10;

$L__BB5_14:
	add.f32 	%f107, %f2, %f16;
	bra.uni 	$L__BB5_15;

$L__BB5_10:
	setp.eq.f32 	%p20, %f4, 0f7F800000;
	@%p20 bra 	$L__BB5_13;
	bra.uni 	$L__BB5_11;

$L__BB5_13:
	setp.gt.f32 	%p23, %f3, 0f3F800000;
	selp.b32 	%r33, 2139095040, 0, %p23;
	xor.b32  	%r34, %r33, 2139095040;
	setp.lt.f32 	%p24, %f16, 0f00000000;
	selp.b32 	%r35, %r34, %r33, %p24;
	mov.b32 	%f103, %r35;
	setp.eq.f32 	%p25, %f2, 0fBF800000;
	selp.f32 	%f107, 0f3F800000, %f103, %p25;
	bra.uni 	$L__BB5_15;

$L__BB5_11:
	setp.neu.f32 	%p21, %f3, 0f7F800000;
	@%p21 bra 	$L__BB5_15;

	setp.ge.f32 	%p22, %f16, 0f00000000;
	selp.b32 	%r30, 2139095040, 0, %p22;
	or.b32  	%r31, %r30, -2147483648;
	selp.b32 	%r32, %r31, %r30, %p1;
	mov.b32 	%f107, %r32;

$L__BB5_15:
	setp.eq.f32 	%p26, %f16, 0f00000000;
	setp.eq.f32 	%p27, %f2, 0f3F800000;
	or.pred  	%p28, %p26, %p27;
	selp.f32 	%f104, 0f3F800000, %f107, %p28;
	mul.lo.s32 	%r36, %r1, %r3;
	mul.wide.s32 	%rd7, %r36, 4;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.f32 	[%rd8], %f104;

$L__BB5_16:
	ret;

}
	// .globl	axpy_kernel
.visible .entry axpy_kernel(
	.param .u32 axpy_kernel_param_0,
	.param .f32 axpy_kernel_param_1,
	.param .u64 axpy_kernel_param_2,
	.param .u32 axpy_kernel_param_3,
	.param .u32 axpy_kernel_param_4,
	.param .u64 axpy_kernel_param_5,
	.param .u32 axpy_kernel_param_6,
	.param .u32 axpy_kernel_param_7
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<5>;
	.reg .b32 	%r<15>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r6, [axpy_kernel_param_0];
	ld.param.f32 	%f1, [axpy_kernel_param_1];
	ld.param.u64 	%rd1, [axpy_kernel_param_2];
	ld.param.u32 	%r2, [axpy_kernel_param_3];
	ld.param.u32 	%r3, [axpy_kernel_param_4];
	ld.param.u64 	%rd2, [axpy_kernel_param_5];
	ld.param.u32 	%r4, [axpy_kernel_param_6];
	ld.param.u32 	%r5, [axpy_kernel_param_7];
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %nctaid.x;
	mov.u32 	%r9, %ctaid.y;
	mad.lo.s32 	%r10, %r9, %r8, %r7;
	mov.u32 	%r11, %ntid.x;
	mov.u32 	%r12, %tid.x;
	mad.lo.s32 	%r1, %r10, %r11, %r12;
	setp.ge.s32 	%p1, %r1, %r6;
	@%p1 bra 	$L__BB6_2;

	cvta.to.global.u64 	%rd3, %rd1;
	mad.lo.s32 	%r13, %r1, %r3, %r2;
	mul.wide.s32 	%rd4, %r13, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.f32 	%f2, [%rd5];
	mad.lo.s32 	%r14, %r1, %r5, %r4;
	cvta.to.global.u64 	%rd6, %rd2;
	mul.wide.s32 	%rd7, %r14, 4;
	add.s64 	%rd8, %rd6, %rd7;
	ld.global.f32 	%f3, [%rd8];
	fma.rn.f32 	%f4, %f2, %f1, %f3;
	st.global.f32 	[%rd8], %f4;

$L__BB6_2:
	ret;

}
	// .globl	scal_add_kernel
.visible .entry scal_add_kernel(
	.param .u32 scal_add_kernel_param_0,
	.param .f32 scal_add_kernel_param_1,
	.param .f32 scal_add_kernel_param_2,
	.param .u64 scal_add_kernel_param_3,
	.param .u32 scal_add_kernel_param_4
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<5>;
	.reg .b32 	%r<11>;
	.reg .b64 	%rd<5>;


	ld.param.u32 	%r3, [scal_add_kernel_param_0];
	ld.param.f32 	%f1, [scal_add_kernel_param_1];
	ld.param.f32 	%f2, [scal_add_kernel_param_2];
	ld.param.u64 	%rd1, [scal_add_kernel_param_3];
	ld.param.u32 	%r2, [scal_add_kernel_param_4];
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %nctaid.x;
	mov.u32 	%r6, %ctaid.y;
	mad.lo.s32 	%r7, %r6, %r5, %r4;
	mov.u32 	%r8, %ntid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r1, %r7, %r8, %r9;
	setp.ge.s32 	%p1, %r1, %r3;
	@%p1 bra 	$L__BB7_2;

	cvta.to.global.u64 	%rd2, %rd1;
	mul.lo.s32 	%r10, %r1, %r2;
	mul.wide.s32 	%rd3, %r10, 4;
	add.s64 	%rd4, %rd2, %rd3;
	ld.global.f32 	%f3, [%rd4];
	fma.rn.f32 	%f4, %f3, %f1, %f2;
	st.global.f32 	[%rd4], %f4;

$L__BB7_2:
	ret;

}
	// .globl	constrain_kernel
.visible .entry constrain_kernel(
	.param .u32 constrain_kernel_param_0,
	.param .f32 constrain_kernel_param_1,
	.param .u64 constrain_kernel_param_2,
	.param .u32 constrain_kernel_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<6>;
	.reg .b32 	%r<11>;
	.reg .b64 	%rd<5>;


	ld.param.u32 	%r3, [constrain_kernel_param_0];
	ld.param.f32 	%f1, [constrain_kernel_param_1];
	ld.param.u64 	%rd1, [constrain_kernel_param_2];
	ld.param.u32 	%r2, [constrain_kernel_param_3];
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %nctaid.x;
	mov.u32 	%r6, %ctaid.y;
	mad.lo.s32 	%r7, %r6, %r5, %r4;
	mov.u32 	%r8, %ntid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r1, %r7, %r8, %r9;
	setp.ge.s32 	%p1, %r1, %r3;
	@%p1 bra 	$L__BB8_2;

	cvta.to.global.u64 	%rd2, %rd1;
	mul.lo.s32 	%r10, %r1, %r2;
	mul.wide.s32 	%rd3, %r10, 4;
	add.s64 	%rd4, %rd2, %rd3;
	ld.global.f32 	%f2, [%rd4];
	neg.f32 	%f3, %f1;
	max.f32 	%f4, %f3, %f2;
	min.f32 	%f5, %f1, %f4;
	st.global.f32 	[%rd4], %f5;

$L__BB8_2:
	ret;

}


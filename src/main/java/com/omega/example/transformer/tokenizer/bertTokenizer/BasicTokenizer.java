package com.omega.example.transformer.tokenizer.bertTokenizer;

import java.util.ArrayList;
import java.util.List;

public class BasicTokenizer implements Tokenizer {
	private boolean do_lower_case = true;
	private List<String> never_split = new ArrayList<String>();
	private boolean tokenize_chinese_chars = true;

	public BasicTokenizer(boolean do_lower_case, List<String> never_split, boolean tokenize_chinese_chars) {
		this.do_lower_case = do_lower_case;
		if (never_split == null) {
			never_split = new ArrayList<String>();
		}
		this.tokenize_chinese_chars = tokenize_chinese_chars;
	}

	public BasicTokenizer() {
	}

	@Override
	public List<String> tokenize(String text) {
		text = TokenizerUtils.clean_text(text);
		if (tokenize_chinese_chars) {
			text = TokenizerUtils.tokenize_chinese_chars(text);
		}
		List<String> orig_tokens = TokenizerUtils.whitespace_tokenize(text);

		List<String> split_tokens = new ArrayList<String>();
		for (String token : orig_tokens) {
			if (do_lower_case && !never_split.contains(token)) {
				token = TokenizerUtils.run_strip_accents(token.toLowerCase());
				split_tokens.addAll(TokenizerUtils.run_split_on_punc(token, never_split));
			}
		}
		return TokenizerUtils.whitespace_tokenize(String.join(" ", split_tokens));
	}

}
